# dataset configuration
# answer_list: data/finetune/vqa/answer_list.json
answer_list: data/finetune/vqa/EarthVQA_answer_list.json
# vqa_root: 'images/coco' 
earthvqa_root: 'images/EarthVQA'
# vg_root: 'images/vg'  
# train_file: [data/finetune/vqa/vqa_train.json, data/finetune/vqa/vqa_val.json, data/finetune/vqa/vg_qa.json]
train_file: [data/finetune/vqa/EarthVQA_train.json, data/finetune/vqa/EarthVQA_val.json]
# val_file: [data/finetune/vqa/vqa_val.json]
val_file: [data/finetune/vqa/EarthVQA_val.json]
# test_file: [data/finetune/vqa/vqa_test.json]
test_file: [data/finetune/vqa/EarthVQA_test.json]

ann_root: 'annotation'
print_freq: 256

# set pretrained as a file path or an url
pretrained: ''

# size of vit model; base or large
vit: 'base'
batch_size_target: 256
batch_size_test: 64
batch_size_train: 16
vit_grad_ckpt: False
vit_ckpt_layer: 0

image_res: 384
max_tokens: 35
k_test: 32 #128
inference: 'rank' # generate에서의 성능은??확인해보기

# optimization config
init_lr: 2e-5
optimizer: {init_lr: 2e-5, weight_decay: 0.05, min_lr: 0}
scheduler: {epochs: 10, num_warmup_steps: 0, sched: cosine}

wandb_data:
  name: mask_65
  project: VQA_EarthVQA_epoch_10
  tags: [mask_65]
